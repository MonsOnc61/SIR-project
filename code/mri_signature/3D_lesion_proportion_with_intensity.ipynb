{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c3491d0",
   "metadata": {},
   "source": [
    "### Intensité et porportion des lésions (01 and 07 -> 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cbcd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path.cwd().parent.parent / \"data\"\n",
    "mslesseg_path = data_path / \"01_MSLesSeg_Dataset\"\n",
    "registration_path = data_path / \"07_registered_aseg_results\"\n",
    "\n",
    "if not registration_path.exists():\n",
    "    raise FileNotFoundError(f\"You must run first the script of 'aseg_t1_registration.py' to generate the registered data\")\n",
    "\n",
    "proportion_dir_path = data_path / \"13_lesion_proportion_with_intensity_csv_dir\"\n",
    "if not proportion_dir_path.exists():\n",
    "    proportion_dir_path.mkdir(parents = True, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f63f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[P10 T1] Lésions : 35\n",
      "CSV généré : P10_T1_T1_lesion_proportion.csv\n",
      "CSV généré : P10_T1_T2_lesion_proportion.csv\n",
      "CSV généré : P10_T1_FLAIR_lesion_proportion.csv\n",
      "[P10 T2] Lésions : 32\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 183\u001b[39m\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m zone \u001b[38;5;129;01min\u001b[39;00m exclude_labels:\n\u001b[32m    181\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m n = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlogical_and\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlesion_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m    \u001b[49m\u001b[43maseg_array\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mzone\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m.sum()\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n > \u001b[32m0\u001b[39m:\n\u001b[32m    190\u001b[39m     zone_name = freesurfer_aseg_labels.get(\n\u001b[32m    191\u001b[39m         zone,\n\u001b[32m    192\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mZone_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzone\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    193\u001b[39m     )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "01 and 07 -> 13\n",
    "Ce script prend envrion 22 minutes.\n",
    "\"\"\"\n",
    "\n",
    "# =============================\n",
    "# INDEXATION DES FICHIERS\n",
    "# =============================\n",
    "\n",
    "aseg_split_path_dict = {}\n",
    "t1_split_path_dict = {}\n",
    "\n",
    "for aseg_path in registration_path.rglob(\"*_aseg.nii.gz\"):\n",
    "    parts = aseg_path.stem.split(\"_\")\n",
    "    arg = tuple(parts[:2]) if len(parts) == 3 else parts[0]\n",
    "    aseg_split_path_dict[arg] = aseg_path\n",
    "\n",
    "\n",
    "for t1_path in mslesseg_path.rglob(\"*_T1.nii.gz\"):\n",
    "    parts = t1_path.stem.split(\"_\")\n",
    "    arg = tuple(parts[:2]) if len(parts) == 3 else parts[0]\n",
    "    t1_split_path_dict[arg] = t1_path\n",
    "\n",
    "\n",
    "# =============================\n",
    "# LUT FREESURFER ASEG\n",
    "# =============================\n",
    "\n",
    "exclude_labels = [0, 4, 5, 43, 44]\n",
    "\n",
    "freesurfer_aseg_labels = {\n",
    "\n",
    "    0: \"Background\",\n",
    "\n",
    "    2: \"Left-Cerebral-White-Matter\",\n",
    "    3: \"Left-Cerebral-Cortex\",\n",
    "    4: \"Left-Lateral-Ventricle\",\n",
    "    5: \"Left-Inf-Lat-Vent\",\n",
    "\n",
    "    7: \"Left-Cerebellum-White-Matter\",\n",
    "    8: \"Left-Cerebellum-Cortex\",\n",
    "\n",
    "    10: \"Left-Thalamus-Proper\",\n",
    "    11: \"Left-Caudate\",\n",
    "    12: \"Left-Putamen\",\n",
    "    13: \"Left-Pallidum\",\n",
    "\n",
    "    14: \"3rd-Ventricle\",\n",
    "    15: \"4th-Ventricle\",\n",
    "    16: \"Brain-Stem\",\n",
    "\n",
    "    17: \"Left-Hippocampus\",\n",
    "    18: \"Left-Amygdala\",\n",
    "\n",
    "    24: \"CSF\",\n",
    "    26: \"Left-Accumbens-area\",\n",
    "    28: \"Left-VentralDC\",\n",
    "\n",
    "    30: \"Left-vessel\",\n",
    "    31: \"Left-choroid-plexus\",\n",
    "\n",
    "    41: \"Right-Cerebral-White-Matter\",\n",
    "    42: \"Right-Cerebral-Cortex\",\n",
    "    43: \"Right-Lateral-Ventricle\",\n",
    "    44: \"Right-Inf-Lat-Vent\",\n",
    "\n",
    "    46: \"Right-Cerebellum-White-Matter\",\n",
    "    47: \"Right-Cerebellum-Cortex\",\n",
    "\n",
    "    49: \"Right-Thalamus-Proper\",\n",
    "    50: \"Right-Caudate\",\n",
    "    51: \"Right-Putamen\",\n",
    "    52: \"Right-Pallidum\",\n",
    "\n",
    "    53: \"Right-Hippocampus\",\n",
    "    54: \"Right-Amygdala\",\n",
    "\n",
    "    58: \"Right-Accumbens-area\",\n",
    "    60: \"Right-VentralDC\",\n",
    "\n",
    "    62: \"Right-vessel\",\n",
    "    63: \"Right-choroid-plexus\",\n",
    "\n",
    "    72: \"5th-Ventricle\",\n",
    "    77: \"WM-hypointensities\",\n",
    "\n",
    "    80: \"non-WM-hypointensities\",\n",
    "    85: \"Optic-Chiasm\",\n",
    "\n",
    "    251: \"CC_Posterior\",\n",
    "    252: \"CC_Mid_Posterior\",\n",
    "    253: \"CC_Central\",\n",
    "    254: \"CC_Mid_Anterior\",\n",
    "    255: \"CC_Anterior\",\n",
    "}\n",
    "\n",
    "\n",
    "# =============================\n",
    "# BOUCLE PRINCIPALE\n",
    "# =============================\n",
    "\n",
    "for split in aseg_split_path_dict.keys():\n",
    "\n",
    "    if split not in t1_split_path_dict:\n",
    "        raise ValueError(f\"T1 manquant pour {split}\")\n",
    "\n",
    "\n",
    "    # Infos patient\n",
    "    if isinstance(split, tuple):\n",
    "        patient, timepoint = split\n",
    "    else:\n",
    "        patient = split\n",
    "        timepoint = \"T1\"\n",
    "\n",
    "\n",
    "    # Fichiers\n",
    "    aseg_path = aseg_split_path_dict[split]\n",
    "    t1_path = t1_split_path_dict[split]\n",
    "\n",
    "    t2_path = t1_path.parent / t1_path.name.replace(\"_T1.nii.gz\", \"_T2.nii.gz\")\n",
    "    flair_path = t1_path.parent / t1_path.name.replace(\"_T1.nii.gz\", \"_FLAIR.nii.gz\")\n",
    "    mask_path = t1_path.parent / t1_path.name.replace(\"_T1.nii.gz\", \"_MASK.nii.gz\")\n",
    "\n",
    "\n",
    "    modalities = {\n",
    "        \"T1\": t1_path,\n",
    "        \"T2\": t2_path,\n",
    "        \"FLAIR\": flair_path,\n",
    "    }\n",
    "\n",
    "\n",
    "    # =============================\n",
    "    # LECTURE IMAGES\n",
    "    # =============================\n",
    "\n",
    "    mask_img = sitk.Cast(\n",
    "        sitk.ReadImage(str(mask_path)) > 0,\n",
    "        sitk.sitkUInt8\n",
    "    )\n",
    "\n",
    "    aseg_img = sitk.ReadImage(str(aseg_path))\n",
    "\n",
    "\n",
    "    mask_cc = sitk.RelabelComponent(\n",
    "        sitk.ConnectedComponent(mask_img)\n",
    "    )\n",
    "\n",
    "\n",
    "    mask_array = sitk.GetArrayFromImage(mask_cc)\n",
    "    aseg_array = sitk.GetArrayFromImage(aseg_img)\n",
    "\n",
    "\n",
    "    spacing = mask_img.GetSpacing()\n",
    "    voxel_volume = spacing[0] * spacing[1] * spacing[2]\n",
    "\n",
    "\n",
    "    num_lesions = int(mask_array.max())\n",
    "\n",
    "    print(f\"[{patient} {timepoint}] Lésions : {num_lesions}\")\n",
    "\n",
    "\n",
    "    # =============================\n",
    "    # PROPORTIONS ANATOMIQUES\n",
    "    # =============================\n",
    "\n",
    "    lesion_zone_proportions = {}\n",
    "\n",
    "    unique_zones = np.unique(aseg_array)\n",
    "\n",
    "\n",
    "    for lesion_id in range(1, num_lesions + 1):\n",
    "\n",
    "        lesion_mask = mask_array == lesion_id\n",
    "        total_voxels = lesion_mask.sum()\n",
    "\n",
    "        zone_props = {}\n",
    "\n",
    "        for zone in unique_zones:\n",
    "\n",
    "            if zone in exclude_labels:\n",
    "                continue\n",
    "\n",
    "            n = np.logical_and(\n",
    "                lesion_mask,\n",
    "                aseg_array == zone\n",
    "            ).sum()\n",
    "\n",
    "            if n > 0:\n",
    "\n",
    "                zone_name = freesurfer_aseg_labels.get(\n",
    "                    zone,\n",
    "                    f\"Zone_{zone}\"\n",
    "                )\n",
    "\n",
    "                zone_props[f\"{zone_name}_prop\"] = round(\n",
    "                    n / total_voxels, 3\n",
    "                )\n",
    "\n",
    "\n",
    "        lesion_zone_proportions[lesion_id] = zone_props\n",
    "\n",
    "\n",
    "    # =============================\n",
    "    # HEADER CSV\n",
    "    # =============================\n",
    "\n",
    "    zone_columns = sorted({\n",
    "        k for props in lesion_zone_proportions.values()\n",
    "        for k in props.keys()\n",
    "    })\n",
    "\n",
    "\n",
    "    header = [\n",
    "        \"patient\",\n",
    "        \"timepoint\",\n",
    "        \"lesion_id\",\n",
    "        \"lesion_volume_mm3\",\n",
    "\n",
    "        \"lesion_mean\",\n",
    "        \"lesion_std\",\n",
    "\n",
    "        \"lesion_min\",\n",
    "        \"lesion_max\",\n",
    "        \"lesion_range\",\n",
    "\n",
    "        \"lesion_skew\",\n",
    "        \"lesion_kurt\",\n",
    "\n",
    "    ] + zone_columns\n",
    "\n",
    "\n",
    "    # =============================\n",
    "    # CSV PAR MODALITÉ\n",
    "    # =============================\n",
    "\n",
    "    for modality, img_path in modalities.items():\n",
    "\n",
    "\n",
    "        # Nom fichier\n",
    "        csv_name = f\"{patient}_{timepoint}_{modality}_lesion_proportion.csv\"\n",
    "        csv_path = proportion_dir_path / csv_name\n",
    "\n",
    "\n",
    "        with open(csv_path, \"w\", newline=\"\") as f:\n",
    "\n",
    "            writer = csv.DictWriter(\n",
    "                f,\n",
    "                fieldnames=header\n",
    "            )\n",
    "\n",
    "            writer.writeheader()\n",
    "\n",
    "\n",
    "            # Lecture image\n",
    "            img = sitk.Cast(\n",
    "                sitk.ReadImage(str(img_path)),\n",
    "                sitk.sitkFloat64\n",
    "            )\n",
    "\n",
    "            img_array = sitk.GetArrayFromImage(img)\n",
    "\n",
    "\n",
    "            # =============================\n",
    "            # PARCOURS LÉSIONS\n",
    "            # =============================\n",
    "\n",
    "            for lesion_id in range(1, num_lesions + 1):\n",
    "\n",
    "                lesion_mask = mask_array == lesion_id\n",
    "                voxels = img_array[lesion_mask]\n",
    "\n",
    "\n",
    "                mean = round(voxels.mean(), 1)\n",
    "                std = round(voxels.std(), 1)\n",
    "\n",
    "                vmin = round(voxels.min(), 1)\n",
    "                vmax = round(voxels.max(), 1)\n",
    "\n",
    "\n",
    "                if voxels.size >= 3 and std > 0:\n",
    "\n",
    "                    centered = voxels - mean\n",
    "\n",
    "                    skew = round(\n",
    "                        np.mean(centered**3) / std**3,\n",
    "                        2\n",
    "                    )\n",
    "\n",
    "                    kurt = round(\n",
    "                        np.mean(centered**4) / std**4 - 3,\n",
    "                        2\n",
    "                    )\n",
    "\n",
    "                else:\n",
    "                    skew, kurt = \"\", \"\"\n",
    "\n",
    "                row = {\n",
    "\n",
    "                    \"patient\": patient,\n",
    "                    \"timepoint\": timepoint,\n",
    "                    \"lesion_id\": lesion_id,\n",
    "\n",
    "                    \"lesion_volume_mm3\": round(\n",
    "                        lesion_mask.sum() * voxel_volume, 1\n",
    "                    ),\n",
    "\n",
    "                    \"lesion_mean\": mean,\n",
    "                    \"lesion_std\": std,\n",
    "\n",
    "                    \"lesion_min\": vmin,\n",
    "                    \"lesion_max\": vmax,\n",
    "\n",
    "                    \"lesion_range\": round(vmax - vmin, 1),\n",
    "\n",
    "                    \"lesion_skew\": skew,\n",
    "                    \"lesion_kurt\": kurt,\n",
    "                }\n",
    "\n",
    "                # Proportions\n",
    "                for col in zone_columns:\n",
    "                    row[col] = lesion_zone_proportions[lesion_id].get(col, 0)\n",
    "\n",
    "                writer.writerow(row)\n",
    "\n",
    "        print(f\"CSV généré : {csv_name}\")\n",
    "\n",
    "print(\"Traitement terminé.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sitk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
