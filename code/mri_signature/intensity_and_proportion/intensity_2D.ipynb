{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed9ddaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.ndimage import label as cc_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1924ccd",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "You must run first the script of 'aseg_t1_registration.py' to generate the registered data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m registration_path \u001b[38;5;241m=\u001b[39m data_path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m07_registered_aseg_results\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m registration_path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must run first the script of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maseg_t1_registration.py\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to generate the registered data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Un CSV par patient (tous timepoints/modalités regroupés) + analyse des lésions en 2D (slice par slice)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m csv_folder_path \u001b[38;5;241m=\u001b[39m data_path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m13_lesion_info_per_patient_csv_2D\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: You must run first the script of 'aseg_t1_registration.py' to generate the registered data"
     ]
    }
   ],
   "source": [
    "data_path = Path.cwd().parent.parent.parent / \"data\"\n",
    "mslesseg_path = data_path / \"01_MSLesSeg_Dataset\"\n",
    "registration_path = data_path / \"17_registered_aseg_results_2D\"\n",
    "\n",
    "if not registration_path.exists():\n",
    "    raise FileNotFoundError(\"You must run first the script of 'aseg_t1_registration.py' to generate the registered data\")\n",
    "\n",
    "# Un CSV par patient (tous timepoints/modalités regroupés) + analyse des lésions en 2D (slice par slice)\n",
    "csv_folder_path = data_path / \"13_lesion_info_per_patient_csv_2D\"\n",
    "csv_folder_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "01 and 07 -> 13\n",
    "Génère un CSV par patient.\n",
    "Analyse des lésions en 2D (composantes connexes slice par slice).\n",
    "\"\"\"\n",
    "\n",
    "# =============================\n",
    "# INDEXATION DES FICHIERS\n",
    "# =============================\n",
    "aseg_split_path_dict = {}\n",
    "t1_split_path_dict = {}\n",
    "\n",
    "for aseg_path in registration_path.rglob(\"*_aseg.nii.gz\"):\n",
    "    parts = aseg_path.stem.split(\"_\")\n",
    "    arg = tuple(parts[:2]) if len(parts) == 3 else parts[0]\n",
    "    aseg_split_path_dict[arg] = aseg_path\n",
    "\n",
    "for t1_path in mslesseg_path.rglob(\"*_t1.nii.gz\"):\n",
    "    # Exemple: \"sub-01_ses-01_t1.nii.gz\" -> (sub-01, ses-01)\n",
    "    parts = t1_path.stem.split(\"_\")\n",
    "    arg = tuple(parts[:2]) if len(parts) >= 2 else parts[0]\n",
    "    t1_split_path_dict[arg] = t1_path\n",
    "\n",
    "# =============================\n",
    "# DICO DES ZONES FREE-SURFER\n",
    "# =============================\n",
    "zone_dict = {\n",
    "    2: \"Left-Cerebral-White-Matter\",\n",
    "    3: \"Left-Cerebral-Cortex\",\n",
    "    4: \"Left-Lateral-Ventricle\",\n",
    "    5: \"Left-Inf-Lat-Vent\",\n",
    "    7: \"Left-Cerebellum-White-Matter\",\n",
    "    8: \"Left-Cerebellum-Cortex\",\n",
    "    10: \"Left-Thalamus-Proper\",\n",
    "    11: \"Left-Caudate\",\n",
    "    12: \"Left-Putamen\",\n",
    "    13: \"Left-Pallidum\",\n",
    "    14: \"3rd-Ventricle\",\n",
    "    15: \"4th-Ventricle\",\n",
    "    16: \"Brain-Stem\",\n",
    "    17: \"Left-Hippocampus\",\n",
    "    18: \"Left-Amygdala\",\n",
    "    24: \"CSF\",\n",
    "    26: \"Left-Accumbens-area\",\n",
    "    28: \"Left-VentralDC\",\n",
    "    30: \"Left-vessel\",\n",
    "    31: \"Left-choroid-plexus\",\n",
    "    41: \"Right-Cerebral-White-Matter\",\n",
    "    42: \"Right-Cerebral-Cortex\",\n",
    "    43: \"Right-Lateral-Ventricle\",\n",
    "    44: \"Right-Inf-Lat-Vent\",\n",
    "    46: \"Right-Cerebellum-White-Matter\",\n",
    "    47: \"Right-Cerebellum-Cortex\",\n",
    "    49: \"Right-Thalamus-Proper\",\n",
    "    50: \"Right-Caudate\",\n",
    "    51: \"Right-Putamen\",\n",
    "    52: \"Right-Pallidum\",\n",
    "    53: \"Right-Hippocampus\",\n",
    "    54: \"Right-Amygdala\",\n",
    "    58: \"Right-Accumbens-area\",\n",
    "    60: \"Right-VentralDC\",\n",
    "    62: \"Right-vessel\",\n",
    "    63: \"Right-choroid-plexus\",\n",
    "    # Zones spécifiques souvent touchées par la SEP\n",
    "    72: \"5th-Ventricle\",\n",
    "    77: \"WM-hypointensities\",\n",
    "    78: \"Left-WM-hypointensities\",\n",
    "    79: \"Right-WM-hypointensities\",\n",
    "    80: \"Non-WM-hypointensities\",\n",
    "    81: \"Left-Non-WM-hypointensities\",\n",
    "    82: \"Right-Non-WM-hypointensities\",\n",
    "    250: \"Fornix\",\n",
    "    251: \"CC_Posterior\",\n",
    "    252: \"CC_Mid_Posterior\",\n",
    "    253: \"CC_Central\",\n",
    "    254: \"CC_Mid_Anterior\",\n",
    "    255: \"CC_Anterior\",\n",
    "}\n",
    "\n",
    "# Colonnes de sortie pour les proportions de recouvrement par zone\n",
    "zone_columns = [f\"prop_{v}\" for v in zone_dict.values()]\n",
    "\n",
    "# =============================\n",
    "# OUTILS / FONCTIONS\n",
    "# =============================\n",
    "def safe_stats(values: np.ndarray) -> dict:\n",
    "    \"\"\"Retourne stats robustes pour un tableau 1D (float).\"\"\"\n",
    "    if values.size == 0:\n",
    "        return {\n",
    "            \"mean\": np.nan,\n",
    "            \"std\": np.nan,\n",
    "            \"median\": np.nan,\n",
    "            \"vmin\": np.nan,\n",
    "            \"vmax\": np.nan,\n",
    "            \"range\": np.nan,\n",
    "            \"skew\": np.nan,\n",
    "            \"kurt\": np.nan,\n",
    "        }\n",
    "    v = values.astype(np.float64)\n",
    "    vmin = float(np.min(v))\n",
    "    vmax = float(np.max(v))\n",
    "    return {\n",
    "        \"mean\": float(np.mean(v)),\n",
    "        \"std\": float(np.std(v)),\n",
    "        \"median\": float(np.median(v)),\n",
    "        \"vmin\": vmin,\n",
    "        \"vmax\": vmax,\n",
    "        \"range\": float(vmax - vmin),\n",
    "        \"skew\": float(skew(v)) if v.size >= 3 else np.nan,\n",
    "        \"kurt\": float(kurtosis(v)) if v.size >= 4 else np.nan,\n",
    "    }\n",
    "\n",
    "\n",
    "def lesion_zone_proportions(lesion_mask: np.ndarray, aseg: np.ndarray) -> dict:\n",
    "    \"\"\"\n",
    "    Proportions du recouvrement de la lésion avec chaque zone.\n",
    "    lesion_mask: binaire 3D (bool)\n",
    "    aseg: labels 3D (int)\n",
    "    Retour: { \"prop_<ZoneName>\": proportion }\n",
    "    \"\"\"\n",
    "    vox = int(np.sum(lesion_mask))\n",
    "    if vox == 0:\n",
    "        return {}\n",
    "\n",
    "    props = {}\n",
    "    for label_id, zone_name in zone_dict.items():\n",
    "        overlap = int(np.sum(lesion_mask & (aseg == label_id)))\n",
    "        props[f\"prop_{zone_name}\"] = overlap / vox\n",
    "    return props\n",
    "\n",
    "\n",
    "def connected_components_2d_slice_by_slice(mask3d: np.ndarray, connectivity: int = 1):\n",
    "    \"\"\"\n",
    "    Détecte les composantes connexes en 2D, indépendamment sur chaque slice axiale.\n",
    "    mask3d: bool 3D (Z, Y, X) ou (k, i, j)\n",
    "    Retour:\n",
    "      - label3d: int 3D avec labels uniques globalement (0 = fond)\n",
    "      - n_components: total composantes\n",
    "    \"\"\"\n",
    "    zdim = mask3d.shape[0]\n",
    "    label3d = np.zeros(mask3d.shape, dtype=np.int32)\n",
    "    current = 0\n",
    "    struct = None\n",
    "    if connectivity == 1:\n",
    "        # 4-connectivité en 2D\n",
    "        struct = np.array([[0,1,0],[1,1,1],[0,1,0]], dtype=np.int32)\n",
    "    else:\n",
    "        # 8-connectivité en 2D\n",
    "        struct = np.ones((3,3), dtype=np.int32)\n",
    "\n",
    "    for z in range(zdim):\n",
    "        lbl2d, n = cc_label(mask3d[z].astype(np.int32), structure=struct)\n",
    "        if n == 0:\n",
    "            continue\n",
    "        # Remap labels 1..n vers current+1..current+n\n",
    "        lbl2d_remap = lbl2d.copy()\n",
    "        for k in range(1, n + 1):\n",
    "            current += 1\n",
    "            lbl2d_remap[lbl2d == k] = current\n",
    "        label3d[z] = lbl2d_remap\n",
    "\n",
    "    return label3d, current\n",
    "\n",
    "\n",
    "# =============================\n",
    "# BOUCLE PATIENTS / TIMEPOINTS\n",
    "# =============================\n",
    "\n",
    "# On regroupe par patient\n",
    "# keys dans t1_split_path_dict / aseg_split_path_dict: (sub-XX, ses-YY)\n",
    "patients = sorted({k[0] if isinstance(k, tuple) else k for k in t1_split_path_dict.keys()})\n",
    "\n",
    "# Colonnes CSV (fixes)\n",
    "base_columns = [\n",
    "    \"patient\",\n",
    "    \"timepoint\",\n",
    "    \"modality\",\n",
    "    \"lesion_id\",\n",
    "    \"lesion_voxels\",\n",
    "    \"lesion_volume_mm3\",\n",
    "    \"lesion_mean\",\n",
    "    \"lesion_std\",\n",
    "    \"lesion_median\",\n",
    "    \"lesion_min\",\n",
    "    \"lesion_max\",\n",
    "    \"lesion_range\",\n",
    "    \"lesion_skew\",\n",
    "    \"lesion_kurt\",\n",
    "]\n",
    "columns = base_columns + zone_columns\n",
    "\n",
    "for patient in patients:\n",
    "    csv_path = csv_folder_path / f\"{patient}_lesions_2D.csv\"\n",
    "\n",
    "    # On cherche tous les timepoints du patient\n",
    "    timepoints = sorted({k[1] for k in t1_split_path_dict.keys() if isinstance(k, tuple) and k[0] == patient})\n",
    "\n",
    "    if len(timepoints) == 0:\n",
    "        # fallback si pas en tuple (cas rare)\n",
    "        print(f\"[WARN] Aucun timepoint trouvé pour {patient}\")\n",
    "        continue\n",
    "\n",
    "    with open(csv_path, \"w\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=columns)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for timepoint in timepoints:\n",
    "            key = (patient, timepoint)\n",
    "\n",
    "            if key not in t1_split_path_dict:\n",
    "                print(f\"[WARN] T1 manquant pour {patient} {timepoint}\")\n",
    "                continue\n",
    "            if key not in aseg_split_path_dict:\n",
    "                print(f\"[WARN] ASEG manquant pour {patient} {timepoint}\")\n",
    "                continue\n",
    "\n",
    "            t1_path = t1_split_path_dict[key]\n",
    "            aseg_path = aseg_split_path_dict[key]\n",
    "\n",
    "            # Lecture images\n",
    "            t1_img = sitk.ReadImage(str(t1_path))\n",
    "            aseg_img = sitk.ReadImage(str(aseg_path))\n",
    "\n",
    "            t1 = sitk.GetArrayFromImage(t1_img).astype(np.float32)  # (Z,Y,X)\n",
    "            aseg = sitk.GetArrayFromImage(aseg_img).astype(np.int32)\n",
    "\n",
    "            # Résolution voxel (mm) => volume voxel mm^3\n",
    "            spacing = t1_img.GetSpacing()  # (X,Y,Z) en SITK\n",
    "            voxel_volume_mm3 = float(spacing[0] * spacing[1] * spacing[2])\n",
    "\n",
    "            # Segmentation lésions : on utilise les labels \"WM-hypointensities\" (77-79) + Non-WM-hypointensities (80-82)\n",
    "            lesion_mask = np.isin(aseg, [77, 78, 79, 80, 81, 82])\n",
    "\n",
    "            # Connected components 2D slice-by-slice\n",
    "            lesion_labels, n_lesions = connected_components_2d_slice_by_slice(lesion_mask, connectivity=1)\n",
    "\n",
    "            lesion_counter = 0\n",
    "            for lesion_id in range(1, n_lesions + 1):\n",
    "                comp = (lesion_labels == lesion_id)\n",
    "                voxels = int(np.sum(comp))\n",
    "                if voxels == 0:\n",
    "                    continue\n",
    "\n",
    "                lesion_counter += 1\n",
    "\n",
    "                # Intensités t1 dans la lésion\n",
    "                vals = t1[comp]\n",
    "                st = safe_stats(vals)\n",
    "\n",
    "                # Proportions par zone\n",
    "                zone_props = lesion_zone_proportions(comp, aseg)\n",
    "\n",
    "                row = {\n",
    "                    \"patient\": patient,\n",
    "                    \"timepoint\": timepoint,\n",
    "                    \"modality\": \"t1\",\n",
    "                    \"lesion_id\": lesion_counter,\n",
    "                    \"lesion_voxels\": voxels,\n",
    "                    \"lesion_volume_mm3\": round(voxels * voxel_volume_mm3, 3),\n",
    "                    \"lesion_mean\": round(st[\"mean\"], 3) if np.isfinite(st[\"mean\"]) else st[\"mean\"],\n",
    "                    \"lesion_std\": round(st[\"std\"], 3) if np.isfinite(st[\"std\"]) else st[\"std\"],\n",
    "                    \"lesion_median\": round(st[\"median\"], 3) if np.isfinite(st[\"median\"]) else st[\"median\"],\n",
    "                    \"lesion_min\": round(st[\"vmin\"], 3) if np.isfinite(st[\"vmin\"]) else st[\"vmin\"],\n",
    "                    \"lesion_max\": round(st[\"vmax\"], 3) if np.isfinite(st[\"vmax\"]) else st[\"vmax\"],\n",
    "                    \"lesion_range\": round(st[\"range\"], 3) if np.isfinite(st[\"range\"]) else st[\"range\"],\n",
    "                    \"lesion_skew\": round(st[\"skew\"], 3) if np.isfinite(st[\"skew\"]) else st[\"skew\"],\n",
    "                    \"lesion_kurt\": round(st[\"kurt\"], 3) if np.isfinite(st[\"kurt\"]) else st[\"kurt\"],\n",
    "                }\n",
    "\n",
    "                for col in zone_columns:\n",
    "                    row[col] = zone_props.get(col, 0.0)\n",
    "\n",
    "                writer.writerow(row)\n",
    "\n",
    "            print(f\"[{patient} {timepoint}] lésions 2D écrites : {lesion_counter}\")\n",
    "\n",
    "    print(f\"CSV généré : {csv_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
