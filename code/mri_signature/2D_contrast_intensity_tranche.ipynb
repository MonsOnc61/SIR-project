{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98582859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing P1 - T1: 18 lesions found.\n",
      "Reports saved in /Users/ilhanghauri/Documents/INSA/COURS/TC4/SIR/SIR-project/data/16_template_txt\n",
      "\n",
      "--- Quick Check ---\n",
      "RAPPORT M√âDICAL: Patient P1 | T1 | L√©sion 5\n",
      "COUPE AXIALE: 76\n",
      "========================================\n",
      "MORPHOLOGIE (2D):\n",
      " - Grand axe: 23.50 mm\n",
      " - Petit axe: 4.60 mm\n",
      "\n",
      "SIGNAL & CONTRASTE:\n",
      " - T1: Moy=144.8, Contrast=2.09\n",
      " - T2: Moy=280.4, Contrast=1.93\n",
      " - FLAIR: Moy=204.2, Contrast=2.91\n",
      "\n",
      "LOCALISATION ANATOMIQUE:\n",
      " - Right-Cerebral-White-Matter (89.4%) | Right-Cerebral-Cortex (7.1%) | WM-hypointensities (3.5%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "from pathlib import Path\n",
    "\n",
    "# Mapping des labels FreeSurfer\n",
    "LABELS_MAP = {\n",
    "    0: \"Background\", 2: \"Left-Cerebral-White-Matter\", 3: \"Left-Cerebral-Cortex\",\n",
    "    4: \"Left-Lateral-Ventricle\", 5: \"Left-Inf-Lat-Vent\", 7: \"Left-Cerebellum-White-Matter\",\n",
    "    8: \"Left-Cerebellum-Cortex\", 10: \"Left-Thalamus-Proper\", 11: \"Left-Caudate\",\n",
    "    12: \"Left-Putamen\", 13: \"Left-Pallidum\", 14: \"3rd-Ventricle\", 15: \"4th-Ventricle\",\n",
    "    16: \"Brain-Stem\", 17: \"Left-Hippocampus\", 18: \"Left-Amygdala\", 24: \"CSF\",\n",
    "    26: \"Left-Accumbens-area\", 28: \"Left-VentralDC\", 30: \"Left-vessel\", 31: \"Left-choroid-plexus\",\n",
    "    41: \"Right-Cerebral-White-Matter\", 42: \"Right-Cerebral-Cortex\", 43: \"Right-Lateral-Ventricle\",\n",
    "    44: \"Right-Inf-Lat-Vent\", 46: \"Right-Cerebellum-White-Matter\", 47: \"Right-Cerebellum-Cortex\",\n",
    "    49: \"Right-Thalamus-Proper\", 50: \"Right-Caudate\", 51: \"Right-Putamen\", 52: \"Right-Pallidum\",\n",
    "    53: \"Right-Hippocampus\", 54: \"Right-Amygdala\", 58: \"Right-Accumbens-area\",\n",
    "    60: \"Right-VentralDC\", 62: \"Right-vessel\", 63: \"Right-choroid-plexus\",\n",
    "    72: \"5th-Ventricle\", 77: \"WM-hypointensities\", 80: \"non-WM-hypointensities\", 85: \"Optic-Chiasm\",\n",
    "    251: \"CC_Posterior\", 252: \"CC_Mid_Posterior\", 253: \"CC_Central\", 254: \"CC_Mid_Anterior\", 255: \"CC_Anterior\",\n",
    "}\n",
    "\n",
    "# --- Setup des chemins ---\n",
    "PATIENT, TP = \"P1\", \"T1\"\n",
    "MODALITIES = [\"T1\", \"T2\", \"FLAIR\"]\n",
    "\n",
    "base_path = Path(f\"/Users/ilhanghauri/Documents/INSA/COURS/TC4/SIR/27919209/MSLesSegDataset/train/{PATIENT}/{TP}\")\n",
    "proj_path = Path(\"/Users/ilhanghauri/Documents/INSA/COURS/TC4/SIR/SIR-project\")\n",
    "\n",
    "aseg_path = proj_path / \"data/07_registered_aseg_results\" / f\"{PATIENT}_{TP}_aseg.nii\"\n",
    "out_dir = proj_path / \"data/16_template_txt\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def compute_2d_stats(img_slice, mask_slice, l_id):\n",
    "    \"\"\"Calcule la morphologie et le contraste sur la coupe cible.\"\"\"\n",
    "    l_zone = (mask_slice == l_id).astype(np.uint8)\n",
    "    if not np.any(l_zone): return None\n",
    "\n",
    "    # Intensit√©s\n",
    "    vals = img_slice[l_zone == 1]\n",
    "    stats = {\"mean\": vals.mean(), \"min\": vals.min(), \"max\": vals.max()}\n",
    "    \n",
    "    # G√©om√©trie via SITK\n",
    "    img_sitk = sitk.GetImageFromArray(l_zone)\n",
    "    shape = sitk.LabelShapeStatisticsImageFilter()\n",
    "    shape.Execute(img_sitk)\n",
    "    \n",
    "    if shape.HasLabel(1):\n",
    "        dims = shape.GetEquivalentEllipsoidDiameter(1)\n",
    "        stats[\"major\"], stats[\"minor\"] = max(dims), min(dims)\n",
    "    else: return None\n",
    "\n",
    "    # Contraste simple (moyenne l√©sion / moyenne reste de la coupe)\n",
    "    bg_mean = img_slice[l_zone == 0].mean()\n",
    "    stats[\"contrast\"] = stats[\"mean\"] / bg_mean if bg_mean > 0 else 1.0\n",
    "    return stats\n",
    "\n",
    "def process_patient():\n",
    "    mask_file = base_path / f\"{PATIENT}_{TP}_MASK.nii.gz\"\n",
    "    if not mask_file.exists():\n",
    "        print(f\"Error: Mask missing -> {mask_file}\")\n",
    "        return\n",
    "\n",
    "    # Chargement volumes\n",
    "    m_img = sitk.ReadImage(str(mask_file))\n",
    "    m_labels = sitk.RelabelComponent(sitk.ConnectedComponent(m_img > 0))\n",
    "    m_arr = sitk.GetArrayFromImage(m_labels)\n",
    "    n_lesions = int(m_arr.max())\n",
    "    \n",
    "    aseg_arr = sitk.GetArrayFromImage(sitk.ReadImage(str(aseg_path))) if aseg_path.exists() else None\n",
    "    if aseg_arr is None: print(\"Warning: No ASEG found, location will be empty.\")\n",
    "\n",
    "    print(f\"Processing {PATIENT} - {TP}: {n_lesions} lesions found.\")\n",
    "\n",
    "    for l_id in range(1, n_lesions + 1):\n",
    "        # On cherche la slice avec le plus de pixels de la l√©sion l_id\n",
    "        l_mask = (m_arr == l_id)\n",
    "        best_z = np.argmax(l_mask.sum(axis=(1, 2)))\n",
    "        \n",
    "        data = {}\n",
    "        for mod in MODALITIES:\n",
    "            p = base_path / f\"{PATIENT}_{TP}_{mod}.nii.gz\"\n",
    "            if p.exists():\n",
    "                img = sitk.GetArrayFromImage(sitk.ReadImage(str(p)))\n",
    "                res = compute_2d_stats(img[best_z], m_arr[best_z], l_id)\n",
    "                if res: data[mod] = res\n",
    "            \n",
    "        if not data: continue\n",
    "\n",
    "        # On prend FLAIR par d√©faut pour la morpho\n",
    "        ref = data.get(\"FLAIR\", list(data.values())[0])\n",
    "        \n",
    "        # Identification anatomique\n",
    "        loc_str = \"N/A\"\n",
    "        if aseg_arr is not None:\n",
    "            l_pixels = aseg_arr[best_z][m_arr[best_z] == l_id]\n",
    "            ids, counts = np.unique(l_pixels, return_counts=True)\n",
    "            loc_list = []\n",
    "            for i, c in zip(ids, counts):\n",
    "                name = LABELS_MAP.get(int(i), f\"ID-{int(i)}\")\n",
    "                loc_list.append(f\"{name} ({100*c/len(l_pixels):.1f}%)\")\n",
    "            loc_str = \" | \".join(loc_list)\n",
    "\n",
    "        # Build du rapport texte\n",
    "        report = [\n",
    "            f\"ID: {PATIENT}_{TP}_L{l_id}\",\n",
    "            f\"Slice index (axial): {best_z}\",\n",
    "            \"-\"*30,\n",
    "            f\"Geometry: {ref['major']:.2f} x {ref['minor']:.2f} mm\",\n",
    "            \"Intensities & Contrast:\"\n",
    "        ]\n",
    "        for mod, s in data.items():\n",
    "            report.append(f\"  {mod:5}: Moy={s['mean']:.1f}, Contrast={s['contrast']:.2f}\")\n",
    "        \n",
    "        report.append(f\"\\nLocation:\\n  {loc_str}\")\n",
    "\n",
    "        out_name = f\"{PATIENT}_{TP}_L{l_id}_desc.txt\"\n",
    "        with open(out_dir / out_name, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"\\n\".join(report))\n",
    "            \n",
    "    print(f\"Reports saved in {out_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_patient()\n",
    "    \n",
    "    # Check rapide du dernier fichier\n",
    "    print(\"\\n--- Quick Check ---\")\n",
    "    txt_files = list(out_dir.glob(\"*.txt\"))\n",
    "    if txt_files:\n",
    "        with open(txt_files[-1], \"r\") as f:\n",
    "            print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3c3b06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ D√©marrage de l'analyse : P1 T1\n",
      "   Analyse L√©sion 1/18...\n",
      "   Analyse L√©sion 2/18...\n",
      "   Analyse L√©sion 3/18...\n",
      "   Analyse L√©sion 4/18...\n",
      "   Analyse L√©sion 5/18...\n",
      "   Analyse L√©sion 6/18...\n",
      "   Analyse L√©sion 7/18...\n",
      "   Analyse L√©sion 8/18...\n",
      "   Analyse L√©sion 9/18...\n",
      "   Analyse L√©sion 10/18...\n",
      "   Analyse L√©sion 11/18...\n",
      "   Analyse L√©sion 12/18...\n",
      "   Analyse L√©sion 13/18...\n",
      "   Analyse L√©sion 14/18...\n",
      "   Analyse L√©sion 15/18...\n",
      "   Analyse L√©sion 16/18...\n",
      "   Analyse L√©sion 17/18...\n",
      "   Analyse L√©sion 18/18...\n",
      "‚úÖ Analyse termin√©e. Dossier : /Users/ilhanghauri/Documents/INSA/COURS/TC4/SIR/SIR-project/data/17_automated_reports\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "from pathlib import Path\n",
    "\n",
    "# =================================================================\n",
    "# 1. MATH√âMATIQUES TCHEBICHEF 3D\n",
    "# =================================================================\n",
    "\n",
    "def tchebichef_polynomials(N, order):\n",
    "    M = np.zeros((order, N))\n",
    "    x = np.arange(N)\n",
    "    M[0, :] = 1.0\n",
    "    if order > 1: M[1, :] = (2.0 * x - N + 1.0) / N\n",
    "    for p in range(2, order):\n",
    "        M[p, :] = ((2.0*p-1.0)*(2.0*x-N+1.0)/(p*N))*M[p-1,:] - ((p-1.0)/p)*(1.0-((p-1.0)**2/(N**2)))*M[p-2,:]\n",
    "    return M\n",
    "\n",
    "def calculate_rho(N, order):\n",
    "    rho = np.zeros(order); rho[0] = N\n",
    "    for p in range(1, order): rho[p] = (N**2-p**2)/(N**2) * (2*p-1)/(2*p+1) * rho[p-1]\n",
    "    return rho\n",
    "\n",
    "def decompose_3d(volume, order):\n",
    "    D, H, W = volume.shape\n",
    "    od, oh, ow = min(order, D), min(order, H), min(order, W)\n",
    "    Md, Mh, Mw = tchebichef_polynomials(D, od), tchebichef_polynomials(H, oh), tchebichef_polynomials(W, ow)\n",
    "    rd, rh, rw = calculate_rho(D, od), calculate_rho(H, oh), calculate_rho(W, ow)\n",
    "    \n",
    "    T_raw = np.einsum('zyx,pz,qy,rx->pqr', volume, Md, Mh, Mw)\n",
    "    norm = 1.0 / np.einsum('p,q,r->pqr', rd, rh, rw)\n",
    "    \n",
    "    T_final = np.zeros((order, order, order))\n",
    "    T_final[:od, :oh, :ow] = T_raw * norm\n",
    "    return T_final\n",
    "\n",
    "# =================================================================\n",
    "# 2. CONFIGURATION ET LABELS\n",
    "# =================================================================\n",
    "\n",
    "LABELS_MAP = {\n",
    "    0: \"Background\", 2: \"Left-Cerebral-White-Matter\", 3: \"Left-Cerebral-Cortex\",\n",
    "    4: \"Left-Lateral-Ventricle\", 7: \"Left-Cerebellum-White-Matter\", 8: \"Left-Cerebellum-Cortex\",\n",
    "    16: \"Brain-Stem\", 17: \"Left-Hippocampus\", 24: \"CSF\", 41: \"Right-Cerebral-White-Matter\",\n",
    "    42: \"Right-Cerebral-Cortex\", 43: \"Right-Lateral-Ventricle\", 251: \"CC_Posterior\", 255: \"CC_Anterior\"\n",
    "}\n",
    "\n",
    "PATIENT, TP = \"P1\", \"T1\"\n",
    "MODALITIES = [\"T1\", \"T2\", \"FLAIR\"]\n",
    "ORDRE_TCHEBY = 10\n",
    "\n",
    "# D√©finition des chemins avec pathlib.Path\n",
    "base_path = Path(f\"/Users/ilhanghauri/Documents/INSA/COURS/TC4/SIR/27919209/MSLesSegDataset/train/{PATIENT}/{TP}\")\n",
    "proj_path = Path(\"/Users/ilhanghauri/Documents/INSA/COURS/TC4/SIR/SIR-project\")\n",
    "\n",
    "aseg_path = proj_path / \"data\" / \"07_registered_aseg_results\" / f\"{PATIENT}_{TP}_aseg.nii\"\n",
    "out_dir = proj_path / \"data\" / \"17_automated_reports\"\n",
    "\n",
    "# Cr√©ation du dossier de sortie\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# =================================================================\n",
    "# 3. PIPELINE AUTOMATIS√â\n",
    "# =================================================================\n",
    "\n",
    "def run_global_analysis():\n",
    "    print(f\"üöÄ D√©marrage de l'analyse : {PATIENT} {TP}\")\n",
    "    \n",
    "    # 1. Chargement du Masque\n",
    "    mask_file = base_path / f\"{PATIENT}_{TP}_MASK.nii.gz\"\n",
    "    if not mask_file.exists():\n",
    "        print(f\"‚ùå Erreur : Masque introuvable √† {mask_file}\")\n",
    "        return\n",
    "\n",
    "    m_img = sitk.ReadImage(str(mask_file))\n",
    "    m_labels = sitk.RelabelComponent(sitk.ConnectedComponent(m_img > 0))\n",
    "    m_arr = sitk.GetArrayFromImage(m_labels)\n",
    "    n_lesions = int(m_arr.max())\n",
    "    \n",
    "    # 2. Chargement de l'Atlas Anatomique (ASEG)\n",
    "    aseg_arr = None\n",
    "    if aseg_path.exists():\n",
    "        aseg_arr = sitk.GetArrayFromImage(sitk.ReadImage(str(aseg_path)))\n",
    "    \n",
    "    # 3. Chargement des Volumes IRM (Dictionnaire de tableaux numpy)\n",
    "    volumes_irm = {}\n",
    "    for mod in MODALITIES:\n",
    "        p = base_path / f\"{PATIENT}_{TP}_{mod}.nii.gz\"\n",
    "        if p.exists():\n",
    "            volumes_irm[mod] = sitk.GetArrayFromImage(sitk.ReadImage(str(p)))\n",
    "\n",
    "    # 4. Boucle sur chaque l√©sion individuelle\n",
    "    for l_id in range(1, n_lesions + 1):\n",
    "        print(f\"   Analyse L√©sion {l_id}/{n_lesions}...\")\n",
    "        \n",
    "        # --- A. D√©coupe de la ROI 3D pour Tchebichef ---\n",
    "        indices = np.where(m_arr == l_id)\n",
    "        z_min, z_max = indices[0].min(), indices[0].max()\n",
    "        y_min, y_max = indices[1].min(), indices[1].max()\n",
    "        x_min, x_max = indices[2].min(), indices[2].max()\n",
    "        \n",
    "        # Extraction du volume (on utilise FLAIR pour la signature de forme)\n",
    "        roi_vol = volumes_irm[\"FLAIR\"][z_min:z_max+1, y_min:y_max+1, x_min:x_max+1]\n",
    "        roi_mask = (m_arr[z_min:z_max+1, y_min:y_max+1, x_min:x_max+1] == l_id)\n",
    "        \n",
    "        # Normalisation pour Tchebichef\n",
    "        roi_final = roi_vol * roi_mask\n",
    "        roi_norm = roi_final / (np.max(roi_final) + 1e-10)\n",
    "        \n",
    "        # Calcul des moments 3D\n",
    "        moments_3d = decompose_3d(roi_norm, ORDRE_TCHEBY)\n",
    "        \n",
    "        # --- B. Analyse sur la Coupe de R√©f√©rence (Best Slice) ---\n",
    "        best_z_local = np.argmax(roi_mask.sum(axis=(1, 2)))\n",
    "        best_z_global = z_min + best_z_local\n",
    "        \n",
    "        # Intensit√©s et Contraste\n",
    "        signal_stats = {}\n",
    "        for mod, vol in volumes_irm.items():\n",
    "            pixels_lesion = vol[best_z_global][m_arr[best_z_global] == l_id]\n",
    "            mean_val = np.mean(pixels_lesion)\n",
    "            # Moyenne du cerveau sain sur la m√™me coupe\n",
    "            bg_val = np.mean(vol[best_z_global][m_arr[best_z_global] == 0])\n",
    "            signal_stats[mod] = {\n",
    "                \"moy\": mean_val, \n",
    "                \"contrast\": mean_val / bg_val if bg_val > 0 else 1.0\n",
    "            }\n",
    "\n",
    "        # Localisation Anatomique (Recouvrement)\n",
    "        loc_str = \"Atlas non disponible\"\n",
    "        if aseg_arr is not None:\n",
    "            pixels_aseg = aseg_arr[best_z_global][m_arr[best_z_global] == l_id]\n",
    "            ids, counts = np.unique(pixels_aseg, return_counts=True)\n",
    "            parts = [f\"{LABELS_MAP.get(int(i), f'ID-{i}')} ({100*c/len(pixels_aseg):.1f}%)\" for i, c in zip(ids, counts)]\n",
    "            loc_str = \" | \".join(parts)\n",
    "\n",
    "        # --- C. √âcriture du Rapport ---\n",
    "        report_lines = [\n",
    "            f\"RAPPORT AUTOMATIS√â : {PATIENT}_{TP}_L{l_id}\",\n",
    "            f\"Localisation (Z-Global): {best_z_global}\",\n",
    "            f\"Dimensions ROI (px): {roi_norm.shape}\",\n",
    "            \"-\"*40,\n",
    "            \"1. MOMENTS DE TCHEBICHEF (3D):\",\n",
    "            f\"   Ordre: {ORDRE_TCHEBY}\",\n",
    "            f\"   Moment d'√©nergie (T000): {moments_3d[0,0,0]:.4f}\",\n",
    "            \"\",\n",
    "            \"2. CARACT√âRISTIQUES DU SIGNAL:\",\n",
    "        ]\n",
    "        for mod, s in signal_stats.items():\n",
    "            report_lines.append(f\"   {mod:5}: Moy={s['moy']:.1f}, Contraste={s['contrast']:.2f}\")\n",
    "            \n",
    "        report_lines.append(f\"\\n3. ANATOMIE:\\n   {loc_str}\")\n",
    "\n",
    "        # Sauvegarde du fichier texte\n",
    "        txt_name = f\"{PATIENT}_{TP}_L{l_id}_full_analysis.txt\"\n",
    "        with open(out_dir / txt_name, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"\\n\".join(report_lines))\n",
    "            \n",
    "        # Sauvegarde de la signature num√©rique pour l'IA (format binaire .npy)\n",
    "        np.save(out_dir / f\"{PATIENT}_{TP}_L{l_id}_moments.npy\", moments_3d)\n",
    "\n",
    "    print(f\"‚úÖ Analyse termin√©e. Dossier : {out_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_global_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f7785fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dossier trouv√©. Il contient 1 fichiers.\n",
      "Voici les 10 premiers fichiers :\n",
      " - P1_T1_aseg.nii\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "PROJET_ROOT = \"/Users/ilhanghauri/Documents/INSA/COURS/TC4/SIR/SIR-project\"\n",
    "ASEG_DIR = os.path.join(PROJET_ROOT, \"data\", \"07_registered_aseg_results\")\n",
    "\n",
    "if os.path.exists(ASEG_DIR):\n",
    "    files = os.listdir(ASEG_DIR)\n",
    "    print(f\"‚úÖ Dossier trouv√©. Il contient {len(files)} fichiers.\")\n",
    "    print(\"Voici les 10 premiers fichiers :\")\n",
    "    for f in files[:10]:\n",
    "        print(f\" - {f}\")\n",
    "else:\n",
    "    print(f\"‚ùå LE DOSSIER N'EXISTE PAS : {ASEG_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sitk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
