{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "81d93872",
      "metadata": {},
      "source": [
        "This script registers all aseg of 02_MSLesSeg_FreeSurfer_output in dimension of 01_MSLesSeg_Dataset and store output into 06_transformix_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1a43b8e5",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from copy import deepcopy\n",
        "import SimpleITK as sitk\n",
        "import subprocess\n",
        "import shutil\n",
        "\n",
        "code_path = Path.cwd().parent\n",
        "data_path = Path.cwd().parent.parent / \"data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aea03438-12f4-41be-a4f0-e4ad34cb2b85",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "02 -> 03 and 04\n",
        "Convert all brain and aseg mgz to nii.gz and store them respectively into 03_brain_nii_results and 04_aseg_nii_results\n",
        "\"\"\"\n",
        "\n",
        "# Create a directory to store converted brain nii.gz files\n",
        "brain_nii_results_path = data_path / \"03_brain_nii_results\"\n",
        "brain_nii_results_path.mkdir(parents = True, exist_ok = True)\n",
        "\n",
        "# Create a directory to store converted aseg nii.gz files\n",
        "aseg_nii_results_path = data_path / \"04_aseg_nii_results\"\n",
        "aseg_nii_results_path.mkdir(parents = True, exist_ok = True)\n",
        "\n",
        "# Convert brain mgz to nii.gz and save them in brain_nii_results\n",
        "freesurfer_path = data_path / \"02_MSLesSeg_FreeSurfer_output\"\n",
        "missing_brain_file = brain_nii_results_path / \"missing_brain_file.txt\" # Log missing brain.mgz files\n",
        "missing_aseg_file = aseg_nii_results_path / \"missing_aseg_file.txt\" # Log missing aseg.mgz files\n",
        "\n",
        "if missing_brain_file.exists():\n",
        "    missing_brain_file.unlink()\n",
        "    \n",
        "if missing_aseg_file.exists():\n",
        "    missing_aseg_file.unlink()\n",
        "    \n",
        "for sub_dir in freesurfer_path.iterdir():\n",
        "    if sub_dir.is_dir():\n",
        "        brain_path = sub_dir / \"mri\" / \"brain.mgz\"\n",
        "        aseg_path = sub_dir / \"mri\" / \"aseg.mgz\"\n",
        "        \n",
        "        if brain_path.exists():\n",
        "            converted_brain_path = brain_nii_results_path / f\"{sub_dir.name}_brain.nii.gz\"\n",
        "            sitk.WriteImage(sitk.ReadImage(str(brain_path)), str(converted_brain_path))\n",
        "        else:\n",
        "            with open(missing_brain_file, \"a\", encoding = \"utf-8\") as f:\n",
        "                f.write(f\"{sub_dir.name} has no brain.mgz in FreeSurfer data\\n\")\n",
        "                \n",
        "        if aseg_path.exists():\n",
        "            converted_aseg_path = aseg_nii_results_path / f\"{sub_dir.name}_aseg.nii.gz\"\n",
        "            sitk.WriteImage(sitk.ReadImage(str(aseg_path)), str(converted_aseg_path))\n",
        "        else:\n",
        "            with open(missing_aseg_file, \"a\", encoding = \"utf-8\") as f:\n",
        "                f.write(f\"{sub_dir.name} has no aseg.mgz in FreeSurfer data\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67309b74",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "01 and 03 and Parameters.T1Brain.affine.txt -> 05\n",
        "Register brain to dimension of Dataset and store results into 05_elastix_results\n",
        "This process could take more or less 25 minutes according to the PC performance\n",
        "\"\"\"\n",
        "\n",
        "# Arrange converted brain nii.gz files in a dictionnary associated with their split name\n",
        "brain_split_path_dict = {} # this dictionnary takes brain split path list as key and its path as value\n",
        "\n",
        "for nii_file in brain_nii_results_path.rglob(\"*.nii.gz\"):\n",
        "    arg = nii_file.name.split(\"_\")\n",
        "    arg[-1] = arg[-1].split(\".\")\n",
        "    arg = tuple(arg[:-1] + arg[-1])\n",
        "    brain_split_path_dict[arg] = nii_file\n",
        "\n",
        "\n",
        "# Arrange converted aseg nii.gz files in a dictionnary associated with their split name\n",
        "aseg_split_path_dict = {} # this dictionnary takes aseg split path list as key and its path as value\n",
        "\n",
        "for nii_file in aseg_nii_results_path.rglob(\"*.nii.gz\"):\n",
        "    arg = nii_file.name.split(\"_\")\n",
        "    arg[-1] = arg[-1].split(\".\")\n",
        "    arg = tuple(arg[:-1] + arg[-1])\n",
        "    aseg_split_path_dict[arg] = nii_file\n",
        "\n",
        "\n",
        "# Arrange T1 dataset nii.gz files in a dictionnary associated with their split name\n",
        "mslesseg_path = data_path / \"01_MSLesSeg_Dataset\"\n",
        "t1_split_path_dict = {}\n",
        "\n",
        "for split_dir in [\"train\", \"test\"]:\n",
        "    split_path = mslesseg_path / split_dir\n",
        "    \n",
        "    if not split_path.exists():\n",
        "        continue\n",
        "    \n",
        "    for irm_path in split_path.rglob(\"*.nii.gz\"):\n",
        "        if irm_path.name.endswith(\"_T1.nii.gz\"):\n",
        "            arg = irm_path.name.split(\"_\")\n",
        "            if len(arg) == 2:\n",
        "                arg.insert(1, \"T1\")\n",
        "            \n",
        "            arg[-1] = arg[-1].split(\".\")\n",
        "            arg = tuple(arg[:-1] + arg[-1])\n",
        "            t1_split_path_dict[arg] = irm_path\n",
        "\n",
        "\n",
        "# Create a directory to store elastix results \n",
        "elastix_results_path = data_path / \"05_elastix_results\"\n",
        "elastix_results_path.mkdir(parents = True, exist_ok = True)\n",
        "\n",
        "\n",
        "# Arrange valid brain nii.gz files that have their corresponding T1 nii.gz files in the dataset\n",
        "valid_brain_split_path_dict = deepcopy(brain_split_path_dict)\n",
        "missing_t1_file = elastix_results_path / \"missing_t1_file.txt\"\n",
        "\n",
        "if missing_t1_file.exists():\n",
        "    missing_t1_file.unlink()\n",
        "    \n",
        "extracted_t1_split = [split[0:2] for split in t1_split_path_dict.keys()] # split[0:2] is (patient_id, timepoint_id)\n",
        "\n",
        "for split in brain_split_path_dict.keys():\n",
        "    if split[0:2] not in extracted_t1_split:\n",
        "        with open(missing_t1_file, \"a\", encoding = \"utf-8\") as f:\n",
        "            f.write(f\"{('_'.join(split[0:3]))} doesn't exist in the dataset\\n\")\n",
        "        valid_brain_split_path_dict.pop((split[0:2] + (\"T1\", \"brain\", \"nii\", \"gz\")), None) # remove invalid brains\n",
        "\n",
        "\n",
        "# Elastix registration\n",
        "t1_map = {split[0:2]: path for split, path in t1_split_path_dict.items()}\n",
        "\n",
        "for split, brain_path in valid_brain_split_path_dict.items():\n",
        "        extracted_split = split[0:2]\n",
        "        t1_path = t1_map.get(extracted_split, None)\n",
        "        \n",
        "        if t1_path is not None:\n",
        "            dir_path = elastix_results_path / f\"{'_'.join(extracted_split + ('T1',))}\"\n",
        "            dir_path.mkdir(parents = True, exist_ok = True)\n",
        "            \n",
        "            cmd = [\n",
        "            \"elastix\",\n",
        "            \"-m\", str(brain_path),\n",
        "            \"-f\", str(t1_path),\n",
        "            \"-p\", \"Parameters.T1Brain.affine.txt\",\n",
        "            \"-out\", str(dir_path)\n",
        "            ]\n",
        "            \n",
        "            result = subprocess.run(cmd, capture_output = True, text = True, shell = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcf1dfe6",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "04 and 05 -> 06\n",
        "Register aseg to dimension of Dataset and store results into 06_transformix_results\n",
        "\"\"\"\n",
        "\n",
        "# Rewrite TransformParameters.0.txt files to use NearestNeighbor interpolation\n",
        "for sub_dir in elastix_results_path.iterdir():\n",
        "    if sub_dir.is_dir():\n",
        "        param_path = sub_dir /\"TransformParameters.0.txt\"\n",
        "        with param_path.open(\"r\", encoding = \"utf-8\") as f:\n",
        "            lines = f.readlines()\n",
        "        \n",
        "        new_lines = []\n",
        "        for line in lines:\n",
        "            if line.strip() == \"(FinalBSplineInterpolationOrder 3)\":\n",
        "                continue\n",
        "            if '(ResampleInterpolator \"FinalBSplineInterpolator\")' in line:\n",
        "                line = '(ResampleInterpolator \"FinalNearestNeighborInterpolator\")\\n'\n",
        "            new_lines.append(line)\n",
        "        \n",
        "        new_param_path = sub_dir / \"New_TransformParameters.0.txt\"\n",
        "        if new_param_path.exists():\n",
        "            new_param_path.unlink()\n",
        "        with new_param_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "            f.writelines(new_lines)\n",
        "\n",
        "\n",
        "# Create a directory to store transformix results\n",
        "transformix_results_path = data_path / \"06_transformix_results\"\n",
        "transformix_results_path.mkdir(parents = True, exist_ok = True)\n",
        "\n",
        "\n",
        "# Transformix registration\n",
        "aseg_map = {split[0:2]: value for (split, value) in aseg_split_path_dict.items()}\n",
        "\n",
        "for sub_dir in aseg_nii_results_path.rglob(\"*.nii.gz\"):\n",
        "    arg = sub_dir.name.split(\"_\")\n",
        "    arg[-1] = arg[-1].split(\".\")\n",
        "    split = tuple(arg[:-1] + arg[-1])\n",
        "    \n",
        "    extracted_split = split[0:2]\n",
        "    aseg_path = aseg_map.get(extracted_split, None)\n",
        "    \n",
        "    if aseg_path is not None:\n",
        "        transformix_dir_path = transformix_results_path / f\"{'_'.join(extracted_split + ('T1',))}\"\n",
        "        transformix_dir_path.mkdir(parents = True, exist_ok = True)\n",
        "        \n",
        "        cmd = [\n",
        "        \"transformix\",\n",
        "        \"-in\", str(aseg_path),\n",
        "        \"-tp\", str(elastix_results_path / f\"{'_'.join(extracted_split + ('T1',))}\" / \"New_TransformParameters.0.txt\"),\n",
        "        \"-out\", str(transformix_dir_path)\n",
        "        ]\n",
        "        \n",
        "        result = subprocess.run(cmd, capture_output = True, text = True, shell = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8dc8cd6",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "06 -> 07\n",
        "Add registered aseg and all missing file logs into 07_registered_aseg_results\n",
        "\"\"\"\n",
        "\n",
        "registered_aseg_path = data_path / \"07_registered_aseg_results\"\n",
        "registered_aseg_path.mkdir(parents = True, exist_ok = True)\n",
        "\n",
        "for sub_dir in transformix_results_path.iterdir():\n",
        "    if not sub_dir.is_dir():\n",
        "        continue\n",
        "\n",
        "    src = sub_dir / \"result.nii.gz\"\n",
        "    if not src.exists():\n",
        "        continue\n",
        "\n",
        "    # Patient information extraction\n",
        "    try:\n",
        "        patient_id, timepoint_id, _ = sub_dir.name.split(\"_\", 2)\n",
        "    except ValueError:\n",
        "        continue  # additional safety check\n",
        "\n",
        "    # Destination path determination\n",
        "    dataset_sub_dir = mslesseg_path / \"train\" / patient_id / timepoint_id\n",
        "    dst = registered_aseg_path / f\"{patient_id}_{timepoint_id}_aseg.nii.gz\"\n",
        "    if not dataset_sub_dir.exists():\n",
        "        dataset_sub_dir = mslesseg_path / \"test\" / patient_id\n",
        "        dst = registered_aseg_path / f\"{patient_id}_aseg.nii.gz\"\n",
        "    if not dataset_sub_dir.exists():\n",
        "        continue  # additional safety check\n",
        "\n",
        "    # Copy and rename the aseg file\n",
        "    shutil.copy2(src, dst)\n",
        "    \n",
        "    # Copy all missing file logs\n",
        "    shutil.copy2(missing_brain_file, registered_aseg_path)\n",
        "    shutil.copy2(missing_aseg_file, registered_aseg_path)\n",
        "    shutil.copy2(missing_t1_file, registered_aseg_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e6e4f4b",
      "metadata": {},
      "source": [
        "CAREFUL, the code below are not mandatory to execute, it's optional."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f1352e2",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "!!!ALERT!!! : This sub-script suppresses all intermediate directories created during the process as 03, 04, 05 and 06\n",
        "Change 'remove' to True if you want to delete them\n",
        "\"\"\"\n",
        "\n",
        "remove = False\n",
        "\n",
        "if remove == True:\n",
        "    shutil.rmtree(brain_nii_results_path)\n",
        "    shutil.rmtree(aseg_nii_results_path)\n",
        "    shutil.rmtree(elastix_results_path)\n",
        "    shutil.rmtree(transformix_results_path)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "sitk",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
